{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dictionary_const :\n",
    "  - key : 용어명(str)\n",
    "  - value : list(str) -> [용어영문명, 영문약어명, 정의]\n",
    "  \n",
    "return_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDefDict(path = 'dataset/행정표준용어.xls') :\n",
    "    # convert dataframe_to_dictionary\n",
    "    # key = 용어명, value = [용어영문명, 영문약어명, 정의]\n",
    "    import pandas as pd\n",
    "    from collections import defaultdict\n",
    "    tmp = pd.read_excel(path, header=1, index_col=0)\n",
    "    \n",
    "    newDict = defaultdict(list)\n",
    "    for idx in tmp.index :\n",
    "        newDict[tmp.at[idx,'용어명']] = [tmp.at[idx,'용어영문명'],tmp.at[idx,'영문약어명'],tmp.at[idx,'정의'] ]\n",
    "        \n",
    "    return newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ = getDefDict('C:/dev/행정표준용어.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SCDRF'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_['2차냉각재'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordDict(path) :\n",
    "    import pandas as pd\n",
    "    from collections import defaultdict\n",
    "    tmp = pd.read_excel(path, sheet_name='단어')\n",
    "    \n",
    "    tmpDict = defaultdict(list)\n",
    "    for idx in tmp.index :\n",
    "        tmpDict[tmp.at[idx,'단어명']] = [tmp.at[idx,'영문명'],tmp.at[idx,'약어명'],tmp.at[idx,'정의']]\n",
    "    \n",
    "    return tmpDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_defaultdicts(origin,addition):\n",
    "    for k,v in addition.items():\n",
    "        if not k in addition:\n",
    "            origin[k] = addition[k]\n",
    "    return origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumStrList(list_) :\n",
    "    res = ''\n",
    "    for txt in list_ :\n",
    "        res += txt\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTermDict(path) :\n",
    "    import pandas as pd\n",
    "    \n",
    "    tmp = pd.read_excel(path, sheet_name='용어')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_spacing_model : konlpy, spacing(DL model)\n",
    "def select_spacing(input_, type_='konlpy') :\n",
    "    if type_.lower() == 'konlpy' :\n",
    "        return getNouns(input_)\n",
    "    elif type_.lower() == 'spacing' :\n",
    "        return predict(input_)\n",
    "    else :\n",
    "        raise print('we have only knolpy, spacing models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make abrv\n",
    "def changeAbrv(text,origin,dict_) :\n",
    "    import re\n",
    "\n",
    "    # delete vowel\n",
    "    v = ['a','e','i','o','u']\n",
    "    tmp = text.lower()[1:]\n",
    "\n",
    "    for ch in v :\n",
    "        tmp = tmp.replace(ch,'')\n",
    "\n",
    "    for ch in tmp:\n",
    "        dup = ch+ch\n",
    "        tmp = re.sub(dup, ch, tmp)\n",
    "    \n",
    "    tmp = re.sub(' ','',tmp)\n",
    "    tmp = (text[0].lower() + tmp).upper()\n",
    "    \n",
    "    result = ''\n",
    "    isFound = False\n",
    "    \n",
    "    for idx in range(3,len(tmp)) :\n",
    "        if not tmp[:idx] in dict_.values() :\n",
    "            result = tmp[:idx]\n",
    "            isFound = True\n",
    "            break\n",
    "    # 마지막까지 단어가 있으면 '_' 추가\n",
    "    if not isFound :\n",
    "        if not tmp in dict_.values() :\n",
    "            result = tmp\n",
    "        else :\n",
    "            result = tmp + '_'\n",
    "            \n",
    "    # dict updated\n",
    "    dict_[origin] = result\n",
    "    \n",
    "    return result,dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpacedKor(input_) :\n",
    "    return '_'.join(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'행과_열의_조합'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSpacedKor(['행과','열의','조합'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bspqw'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "txt = 'aebsopiouqwe'\n",
    "regex = re.compile('[^aeiou]')\n",
    "''.join(regex.findall(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abbreviate(eng) :\n",
    "    import re\n",
    "    # except first_charactor\n",
    "    tmp = eng.lower()[1:]\n",
    "    \n",
    "    # del vowel\n",
    "    regex = re.compile('[^aeiou]')\n",
    "    tmp = ''.join(regex.findall(eng))\n",
    "    \n",
    "    # del dupplicate_char\n",
    "    for ch in tmp:\n",
    "        dup = ch+ch\n",
    "        tmp = re.sub(dup, ch, tmp)\n",
    "    \n",
    "    # del blank\n",
    "    return re.sub(' ','',tmp).upper()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BDSQWPQWKJ'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abbreviate('abdsoiqwuepoqwkj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_abbr(eng,kor,dict_) :\n",
    "    # abbreviate 완성되야함\n",
    "    \n",
    "    isFound = False\n",
    "    \n",
    "    tmp_abr = abbreviate(eng)\n",
    "    for idx in range(3,len(tmp_abr)) :\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_kor2abr(input_, dict_ ) :\n",
    "    tmp_spacedAbr = ''\n",
    "    tmp_spacedEng = ''\n",
    "    \n",
    "    if input_ != [] :\n",
    "        for idx in range(len(input_),0,-1) :\n",
    "            tmpTxt = sumStrList(list_[:idx])\n",
    "            if tmpTxt in dict_.keys() :\n",
    "                tmp_spacedEng += dict_[tmpTxt][0] + '_'\n",
    "                tmp_spacedAbr += dict_[tmpTxt][1] + '_'\n",
    "                if idx != len(input_) :\n",
    "                    sub_abr, sub_eng, dict_ = convert_kor2abr(input_[idx:], dict_)\n",
    "                    tmp_spacedAbr += sub_abr\n",
    "                    tmp_spacedEng += sub_eng\n",
    "                break\n",
    "                    \n",
    "            if idx == 1 :\n",
    "                tmp_eng = translate_by_papago_api(tmpTxt)\n",
    "                tmp_spacedEng += tmp_eng + '_'\n",
    "                \n",
    "                if idx != len(input_) : \n",
    "                    sub_abr, sub_eng, dict_ = convert_kor2abr(input_[idx:],dict_)\n",
    "                    # 약어변경 함수(convert_abbr)\n",
    "                    tmp_spacedAbr += sub_abr\n",
    "                    tmp_spacedEng += sub_eng\n",
    "                \n",
    "                    \n",
    "        if tmp_spacedAbr[-1] == '_' :\n",
    "            tmp_spacedAbr = tmp_spacedAbr[:-1]\n",
    "            tmp_spacedEng = tmp_spacedEng[:-1]\n",
    "            \n",
    "    return tmp_spacedAbr, tmp_spacedEng, dict_\n",
    "        \n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make abrv\n",
    "def changeAbrv(text,origin,dict_) :\n",
    "    import re\n",
    "\n",
    "    v = ['a','e','i','o','u']\n",
    "    tmp = text.lower()[1:]\n",
    "\n",
    "    for ch in v :\n",
    "        tmp = tmp.replace(ch,'')\n",
    "\n",
    "    for ch in tmp:\n",
    "        dup = ch+ch\n",
    "        tmp = re.sub(dup, ch, tmp)\n",
    "    \n",
    "    tmp = re.sub(' ','',tmp)\n",
    "    tmp = (text[0].lower() + tmp).upper()\n",
    "    \n",
    "    result = ''\n",
    "    isFound = False\n",
    "    \n",
    "    for idx in range(3,len(tmp)) :\n",
    "        if not tmp[:idx] in dict_.values() :\n",
    "            result = tmp[:idx]\n",
    "            isFound = True\n",
    "            break\n",
    "    # 마지막까지 단어가 있으면 '_' 추가\n",
    "    if not isFound :\n",
    "        if not tmp in dict_.values() :\n",
    "            result = tmp\n",
    "        else :\n",
    "            result = tmp + '_'\n",
    "            \n",
    "    # dict updated\n",
    "    dict_[origin] = result\n",
    "    \n",
    "    return result,dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "default_ = getDefDict('C:/dev/행정표준용어.xls')\n",
    "tmp = pd.read_excel('C:/dev/행정표준용어.xls', header=1, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "tmpDict =  pd.read_excel('C:/dev/dataset/template.xlsx', header=1,sheet_name='단어')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict = defaultdict(list)\n",
    "\n",
    "for idx in tmp.index :\n",
    "    tmp_dict[tmp.at[idx,'용어명']] = [tmp.at[idx,'용어영문명'],tmp.at[idx,'영문약어명'],tmp.at[idx,'정의'] ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14111"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>단어명</th>\n",
       "      <th>영문명</th>\n",
       "      <th>약어명</th>\n",
       "      <th>정의</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [단어명, 영문명, 약어명, 정의]\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate_function\n",
    "def translate_by_selenium_naver(text) :\n",
    "    from selenium import webdriver\n",
    "    import urllib.request\n",
    "    import requests\n",
    "    import time\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    chromedriver_dir = 'C:/dev/driver/chromedriver.exe'\n",
    "    driver = webdriver.Chrome(chromedriver_dir)\n",
    "    \n",
    "    driver.get(\"https://papago.naver.com/\")\n",
    "    driver.implicitly_wait(3)\n",
    "    driver.find_element_by_id('txtSource').send_keys(text)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    output_ = driver.find_element_by_id('txtTarget').text\n",
    "    \n",
    "    driver.close()\n",
    "    \n",
    "    return output_\n",
    "\n",
    "def translate_by_selenium(text) :\n",
    "    from selenium import webdriver\n",
    "    import urllib.request\n",
    "    import requests\n",
    "    import time\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    chromedriver_dir = 'C:\\dev\\driver\\chromedriver.exe'\n",
    "    driver = webdriver.Chrome(chromedriver_dir)\n",
    "\n",
    "    driver.get(\"https://translate.google.com/\")\n",
    "\n",
    "    driver.find_element_by_id('sugg-item-en').click()\n",
    "    driver.find_element_by_id('sugg-item-ko').click()\n",
    "\n",
    "    driver.find_element_by_id('source').send_keys(text)\n",
    "\n",
    "    time.sleep(1)\n",
    "    source = driver.page_source\n",
    "    soupData = BeautifulSoup(source,'html.parser')\n",
    "    \n",
    "    driver.close()\n",
    "\n",
    "    return soupData.find('span',class_='tlid-translation translation').text\n",
    "\n",
    "def translate_by_papago_api(text) :\n",
    "    import os\n",
    "    import sys\n",
    "    import urllib.request\n",
    "    import json\n",
    "    \n",
    "    client_id = \"bONH_8tRvIGnJbn7o966\"\n",
    "    client_secret = \"zuoA87y5rv\"\n",
    "    \n",
    "    output_ = ''\n",
    "    encText = urllib.parse.quote(text)\n",
    "    data = \"source=ko&target=en&text=\" + encText\n",
    "    url = \"https://openapi.naver.com/v1/papago/n2mt\"\n",
    "    request = urllib.request.Request(url)\n",
    "    request.add_header(\"X-Naver-Client-Id\",client_id)\n",
    "    request.add_header(\"X-Naver-Client-Secret\",client_secret)\n",
    "    response = urllib.request.urlopen(request, data=data.encode(\"utf-8\"))\n",
    "    rescode = response.getcode()\n",
    "    if(rescode==200):\n",
    "        response_body = response.read()\n",
    "        str2dict = json.loads(response_body.decode('utf-8'))\n",
    "        output_ = str2dict['message']['result']['translatedText']\n",
    "    else:\n",
    "        output_ = \"Error Code:\" +rescode\n",
    "\n",
    "    return output_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition_dictionary crawling\n",
    "def get_definition(text) :\n",
    "    from selenium import webdriver\n",
    "    import urllib.request\n",
    "    import requests\n",
    "    import time\n",
    "    \n",
    "    chromedriver_dir = 'C:/dev/driver/chromedriver.exe'\n",
    "    driver = webdriver.Chrome(chromedriver_dir)\n",
    "    \n",
    "    driver.get(\"https://ko.dict.naver.com/#/main\")\n",
    "    \n",
    "    driver.find_element_by_id('ac_input').send_keys(text)\n",
    "    \n",
    "    driver.find_element_by_xpath(\"//button[@class='btn_search']\").click()\n",
    "    \n",
    "    time.sleep(1)\n",
    "    driver.find_element_by_xpath(\"//div[@class='component_keyword has-saving-function']/div[@class='row']/div[@class='origin']/a\").click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    try :\n",
    "        output_ = driver.find_element_by_xpath(\"//ul[@class='mean_list my_mean_list']\").text\n",
    "    except : \n",
    "        output_ = driver.find_element_by_xpath(\"//li[@class='mean_item']/div[@class='mean_desc']/p[@class='cont']\").text\n",
    "    finally :\n",
    "        driver.close()\n",
    "    \n",
    "    return output_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make abrv\n",
    "def changeAbrv(text,origin,dict_) :\n",
    "    import re\n",
    "\n",
    "    v = ['a','e','i','o','u']\n",
    "    tmp = text.lower()[1:]\n",
    "\n",
    "    for ch in v :\n",
    "        tmp = tmp.replace(ch,'')\n",
    "\n",
    "    for ch in tmp:\n",
    "        dup = ch+ch\n",
    "        tmp = re.sub(dup, ch, tmp)\n",
    "    \n",
    "    tmp = re.sub(' ','',tmp)\n",
    "    tmp = (text[0].lower() + tmp).upper()\n",
    "    \n",
    "    result = ''\n",
    "    isFound = False\n",
    "    \n",
    "    for idx in range(3,len(tmp)) :\n",
    "        if not tmp[:idx] in dict_.values() :\n",
    "            result = tmp[:idx]\n",
    "            isFound = True\n",
    "            break\n",
    "    \n",
    "    # 마지막까지 단어가 있으면 '_' 추가\n",
    "    if not isFound :\n",
    "        if not tmp in dict_.values() :\n",
    "            result = tmp\n",
    "        else :\n",
    "            result = tmp + '_'\n",
    "            \n",
    "    # dict updated\n",
    "    dict_[origin] = result\n",
    "    \n",
    "    return result,dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_path end check (if use '/')\n",
    "def dirEnd_check(path) :\n",
    "    if path[-1] != '/' :\n",
    "        path += '/'\n",
    "    return path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFile_v2(inputDict, input_path,output_path='output') :\n",
    "    import pandas as pd\n",
    "    \n",
    "    input_ = pd.read_excel(input_path)\n",
    "    if output_path[input_path.rfind('/'):].find('.') == -1 :\n",
    "        output_path += input_path[input_path.rfind('/'):]\n",
    "\n",
    "    defDict = getDataDict()\n",
    "    newDict = {}\n",
    "    \n",
    "    for idx in input_['output'].isnull().index :\n",
    "        tmp, inputDict,defDict,newDict = convert_v4(input_.at[idx,'input'],inputDict,defDict,newDict)\n",
    "        input_.output[idx] = tmp\n",
    "        \n",
    "    input_.to_excel(output_path,index=False)\n",
    "    outputDict(newDict,output_path[:output_path.rfind('/')]+'/newDict.xlsx')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class spacing_konlpy()\n",
    "def getNouns(input_) :\n",
    "    from konlpy.tag import Okt\n",
    "    tl = Okt().pos(input_)\n",
    "    rl = []\n",
    "    tmp =''\n",
    "\n",
    "    for idx in range(len(tl)) :    \n",
    "        if tl[idx][1] == 'Noun' :\n",
    "            if tmp != '' :\n",
    "                rl.append(tmp)\n",
    "            rl.append(tl[idx][0])\n",
    "            tmp = ''\n",
    "        else :\n",
    "            tmp += str(tl[idx][0])\n",
    "    \n",
    "    if tmp != '' :\n",
    "        rl.append(tmp)\n",
    "            \n",
    "    return rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_spacing(type_, input_) :\n",
    "    if type_ == 'konlpy' :\n",
    "        return getNouns(input_)\n",
    "#     elif type_ == 'myspacing' :\n",
    "#         return spacing\n",
    "    else :\n",
    "        raise print('error')\n",
    "\n",
    "def convert(input_,inputDict,defDict,newDict) :\n",
    "    result = ''\n",
    "    if input_ != [] :\n",
    "        for idx in range(len(input_),0,-1) :\n",
    "            tmpTxt = sumStrList(list_[:idx])\n",
    "            if tmpTxt in inputDict.keys() :\n",
    "                result += inputDict[tmpTxt] + '_'\n",
    "                if idx != len(input_) :\n",
    "                    resTmp,inputDict,defDict,newDict = convert(sumStrList(input_[idx:]),inputDict,\n",
    "                                                                  defDict,newDict)\n",
    "                    result += resTmp\n",
    "                break\n",
    "            elif tmpTxt in defDict.keys() :\n",
    "                result += defDict[tmpTxt] + '_'\n",
    "                if idx != len(input_) :\n",
    "                    resTmp,inputDict,defDict,newDict = convert(sumStrList(input_[idx:]),inputDict,\n",
    "                                                                  defDict,newDict)\n",
    "                    result += resTmp\n",
    "                break\n",
    "            elif tmpTxt in newDict.keys() :\n",
    "                result += newDict[tmpTxt] + '_'\n",
    "                if idx != len(input_) :\n",
    "                    resTmp,inputDict,defDict,newDict = convert(sumStrList(input_[idx:]),inputDict,\n",
    "                                                                  defDict,newDict)\n",
    "                    result += resTmp\n",
    "                break\n",
    "\n",
    "            if idx == 1 :\n",
    "                tmp,newDict = changeAbrv_v2(translate_by_papago_api(tmpTxt),tmpTxt,newDict)\n",
    "                result += tmp + '_'\n",
    "                if idx != len(input_) :\n",
    "                    resTmp,inputDict,defDict,newDict = convert(sumStrList(input_[idx:]),inputDict,\n",
    "                                                                  defDict,newDict)\n",
    "                    result += resTmp\n",
    "                    \n",
    "                    \n",
    "        if result[-1] == '_' :\n",
    "            result = result[:-1]\n",
    "    \n",
    "    return result, inputDict, defDict, newDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
